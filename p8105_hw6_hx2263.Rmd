---
title: "p8105_hw6_hx2263"
author: "Tiffany Xi"
date: "11/19/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library("leaps")
theme_set(theme_bw() + theme(legend.position = "bottom") + theme(plot.title = element_text(hjust = 0.5)))
```

# Problem 1

### Import data

```{r data_import, message=FALSE}
raw_homicide = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

### Data tidy

```{r warning=FALSE}
homicide_tidy = 
  raw_homicide %>% 
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, ", ", state)) %>% 
  mutate(status = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) %>%
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white"),
         victim_race = fct_relevel(victim_race, ref = "white"),
         victim_age = as.numeric(victim_age))
```

After data cleaning, the tidy dataset consists `r nrow(homicide_tidy)` rows by `r ncol(homicide_tidy)` columns.

### glm in Baltimore, MD

Logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors

```{r}
baltimore_log = 
  homicide_tidy %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(status ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

baltimore_log %>% broom::tidy()
```

the estimate and CI of the **adjusted odds ratio** for solving homicides comparing non-white victims to white victims keeping all other variables fixed

```{r}
baltimore_OR_CI = 
  baltimore_log %>% 
  broom::tidy(conf.int = TRUE) %>% 
  mutate(OR = exp(estimate),
         conf_lower = exp(conf.low),
         conf_upper = exp(conf.high)) %>% 
  select(term, OR, conf_lower, conf_upper) %>% 
  filter(term == "victim_racenon-white") %>%
  knitr::kable(digits = 3)

baltimore_OR_CI
```

**Comment**:
According to the result of linear regression model, the adjusted odds ratio of solved homicides in Baltimore, MD which the victim race is non-white is 0.441 times the adjusted odds ratio of solved homicides when the victim race is white. 95% CI is between 0.312 and 0.62.

### glm for each cities

```{r each_city, warning = FALSE}
eachcity_log = 
  homicide_tidy %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(status ~ victim_age + victim_sex + victim_race,
                                   data = ., family = binomial())),
         model_ci = map(models, broom::confint_tidy),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(OR = round(exp(estimate), 3),
         conf_lower = round(exp(conf.low), 3),
         conf_upper = round(exp(conf.high), 3)) %>% 
  select(city_state, OR, conf_lower, conf_upper)

head(eachcity_log)
```

### Visualization 

```{r plot, fig.width = 10, fig.height = 8}
eachcity_log %>%
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  coord_flip() + 
  geom_point(size = 1.5, shape = 18, fill = "white") +
  geom_errorbar(mapping = aes(ymin = conf_lower, ymax = conf_upper)) +
  geom_hline(yintercept = 1, alpha = 0.4, color = "red") +
  labs(
        title = "Estimated OR and CIs for Each City",
        subtitle = "for solving homicides comparing non-white vs white victims",
        x = "City State",
        y = "Estimated Odd Ratio and CI",
        caption = "Data from the github package"
      ) +
    theme(axis.text = element_text(size = 8))
```

**Comment**:
According to the plot above, we can see that the adjusted OR in most cities (44 out of 47) of solving homicides comparing non-white to white victims is less than 1, which means in most cities, homicides with non-white victim are less likely to be solved than those with white victims. Also, cities with higher OR estimate tend to have wider confidence interval. This indicates the estimate in cities like `Tampa, FL`, `Durham, NC` are less precise than `Boston, MA`, `Omaha, NE`. 

# Problem 2

### Load and clean the data

```{r message = FALSE, cache = TRUE}
raw_birthweight = read_csv(file = "./data/birthweight.csv")

birthweight_tidy = 
  raw_birthweight %>% 
  janitor::clean_names() %>% 
  mutate(babysex = as.factor(ifelse(babysex == 1, "Male", "Female")),
         frace = as.factor(frace),
         frace = recode_factor(frace, `1` = 'White', `2` = 'Black', 
                               `3` = 'Asian', `4` = 'Puerto Rican', 
                               `8` = 'Other', `9` = 'Unknown'),
         malform = as.factor(ifelse(malform == 1, "present", "absent")),
         mrace = as.factor(mrace),
         mrace = recode_factor(mrace, `1` = 'White', `2` = 'Black',
                               `3` = 'Asian', `4` = 'Puerto Rican',
                               `8` = 'Other')) %>% 
  select(bwt, everything()) 

# check for missing data
sum(is.na(birthweight_tidy))
```


```{r corr}
cor(birthweight_tidy %>% select(-babysex, -frace, -mrace, -malform, -pnumlbw, -pnumsga, -parity))[,1]
```

According to the correlation results, `bhead` and `blength` are highly related with `bwt`


Propose a regression model for birthweight.

### Apply **Stepwise Elimination**--data-driven model-building process

```{r stepwise}
mult.fit <- lm(bwt ~ ., data = birthweight_tidy)
step(mult.fit, direction='backward')

model_my = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks 
           + mheight + mrace + parity + ppwt + smoken, data = birthweight_tidy)

summary(model_my)
```

### plot of model residuals against fitted values

```{r fig.width = 10, fig.height = 8}
birthweight_tidy %>% 
  add_predictions(model_my) %>% 
  add_residuals(model_my) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.25) +
  labs(
        title = "Plot of Model Residuals VS Fitted Values",
        x = "Predictions",
        y = "Residuals",
        caption = "Data from the github package"
      ) 
```

**Comment**:
Residual values bounce around 0, which is as expected. Residuals form a horizontal ‘band’ around zero: above and below. But not in random pattern, not evenly distributed around 0.


### Compare with two other model

One using length at birth and gestational age as predictors (main effects only)

```{r}
model_1 = lm(bwt ~ blength + gaweeks, data = birthweight_tidy)
summary(model_1)
```

One using head circumference, length, sex, and all interactions (including the three-way interaction)

```{r}
model_2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex +  bhead*babysex + bhead*blength*babysex, data = birthweight_tidy)
summary(model_2)
```

### Comparing based on cross-validated prediction error

```{r warning=FALSE}
cv_df =
  crossv_mc(birthweight_tidy, 1000) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(model_my = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt 
                                   + fincome + gaweeks + mheight + mrace 
                                   + parity + ppwt + smoken, data = .x)),
         model_1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_2  = map(train, ~lm(bwt ~ bhead + blength + babysex 
                                   + bhead*blength + blength*babysex + bhead*babysex 
                                   + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_my= map2_dbl(model_my,test, ~rmse(model = .x, data = .y)),
         rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin(fill = "gold")
```

**Comment**:

I focused on RMSE to compare three models, and the plot above shows the distribution of RMSE values for each candidate model. Based on these results, there’s clearly some improvement in predictive accuracy gained by using my model, model 1 is the worst for its highest RMSE.
